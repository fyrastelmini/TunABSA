{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCaKP5LsLinH",
        "outputId": "a6a433f1-b574-41f1-dcb7-e56d431e09aa"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.27.1-py3-none-any.whl (6.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.25.1)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.2-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.9.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.13.2 tokenizers-0.13.2 transformers-4.27.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bK9DS-KBGnST",
        "outputId": "dd18ea3d-bab0-4594-9b3c-f9c4e1c276be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import _pickle as cPickle\n",
        "import ast\n",
        "\n",
        "from collections import defaultdict\n",
        "import re\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import sys\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Dense, Input, Flatten\n",
        "from keras.layers import Conv1D, MaxPooling1D, Embedding, Concatenate, Dropout, LSTM, GRU, Bidirectional, TimeDistributed\n",
        "from keras.models import Model\n",
        "import transformers as tr\n",
        "\n",
        "from keras import backend as K\n",
        "\n",
        "#from keras.engine.topology import Layer, InputSpec\n",
        "from keras import initializers\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/nlp/dataset_out.csv')\n",
        "df['subject_mask'] = df['subject_mask'].apply(ast.literal_eval)\n",
        "df['polarized_mask'] = df['polarized_mask'].apply(ast.literal_eval)\n",
        "def get_features(sentence,entity_list,polarity_list):\n",
        "    tokenizer = tr.BertTokenizer.from_pretrained(\"ziedsb19/tunbert_zied\")\n",
        "    new_indexer1=[] #to store polarity tokens\n",
        "    new_indexer2=[] #to store entity tokens\n",
        "    words=sentence.split(\" \")\n",
        "    for w,j,g in zip(words,polarity_list,entity_list):\n",
        "        l=len(tokenizer(w)[\"input_ids\"])-2 #remove 2&3 tokens\n",
        "    \n",
        "        for k in range(l):\n",
        "            new_indexer1.append(j)\n",
        "            new_indexer2.append(g)\n",
        "    tokens=tokenizer(sentence)[\"input_ids\"]\n",
        "    tokens.remove(2)\n",
        "    tokens.remove(3)\n",
        "    return(tokens,new_indexer2,new_indexer1)\n",
        "list_tokens=[]\n",
        "list_subject_mask=[]\n",
        "list_polarizd_mask=[]\n",
        "for l in range(44):\n",
        "  i,j,k=get_features(df.iloc[l][\"sentence\"],df.iloc[l][\"subject_mask\"],df.iloc[l][\"polarized_mask\"])\n",
        "  list_tokens.append(i)\n",
        "  list_subject_mask.append(j)\n",
        "  list_polarizd_mask.append(k)\n",
        "df[\"tokens\"]=list_tokens\n",
        "df[\"subject_mask_tokens\"]=list_subject_mask\n",
        "df[\"polarized_mask_tokens\"]=list_polarizd_mask\n",
        "df = df.drop(['subject_mask', 'polarized_mask'], axis=1)\n",
        "df.to_csv(\"updated_data.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "ryPzDUCALddp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "0kFJGw33amFE",
        "outputId": "949d3570-e36e-44c8-e937-689ac81637d6"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             sentence  label  \\\n",
              "0  nchallah rabi m3ana bravo big boss      1   \n",
              "1       aweel cmnyr bravooo sanfouuur      1   \n",
              "2                  5amamt ta3mil pron      0   \n",
              "3     andhomm rabb karim razzag rahim      1   \n",
              "4                      bravo mr selim      1   \n",
              "\n",
              "                                              tokens  \\\n",
              "0                  [920, 339, 1595, 662, 3438, 4184]   \n",
              "1  [909, 3620, 12710, 1889, 137, 7759, 2032, 490,...   \n",
              "2                            [12629, 5430, 439, 146]   \n",
              "3  [8322, 155, 11677, 5673, 261, 6127, 149, 1742,...   \n",
              "4                                  [662, 1354, 8552]   \n",
              "\n",
              "              subject_mask_tokens           polarized_mask_tokens  \n",
              "0              [0, 0, 0, 0, 1, 1]              [0, 0, 0, 1, 0, 0]  \n",
              "1  [0, 0, 0, 0, 0, 0, 1, 1, 1, 1]  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]  \n",
              "2                    [0, 0, 0, 0]                    [0, 0, 0, 0]  \n",
              "3     [0, 0, 1, 0, 0, 0, 0, 0, 0]     [0, 0, 0, 1, 1, 1, 1, 1, 1]  \n",
              "4                       [0, 1, 1]                       [1, 0, 0]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-72816398-39c6-45fd-871b-9db78f42a56a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "      <th>tokens</th>\n",
              "      <th>subject_mask_tokens</th>\n",
              "      <th>polarized_mask_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>nchallah rabi m3ana bravo big boss</td>\n",
              "      <td>1</td>\n",
              "      <td>[920, 339, 1595, 662, 3438, 4184]</td>\n",
              "      <td>[0, 0, 0, 0, 1, 1]</td>\n",
              "      <td>[0, 0, 0, 1, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>aweel cmnyr bravooo sanfouuur</td>\n",
              "      <td>1</td>\n",
              "      <td>[909, 3620, 12710, 1889, 137, 7759, 2032, 490,...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 1, 1, 1, 1]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5amamt ta3mil pron</td>\n",
              "      <td>0</td>\n",
              "      <td>[12629, 5430, 439, 146]</td>\n",
              "      <td>[0, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>andhomm rabb karim razzag rahim</td>\n",
              "      <td>1</td>\n",
              "      <td>[8322, 155, 11677, 5673, 261, 6127, 149, 1742,...</td>\n",
              "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 1, 1, 1, 1, 1, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bravo mr selim</td>\n",
              "      <td>1</td>\n",
              "      <td>[662, 1354, 8552]</td>\n",
              "      <td>[0, 1, 1]</td>\n",
              "      <td>[1, 0, 0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-72816398-39c6-45fd-871b-9db78f42a56a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-72816398-39c6-45fd-871b-9db78f42a56a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-72816398-39c6-45fd-871b-9db78f42a56a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_sequence_length = 100\n",
        "vocab_size = 10000\n",
        "embedding_dim = 128\n",
        "gru_units = 64\n",
        "train_val_split=0.8"
      ],
      "metadata": {
        "id": "WY-h3C7YLnhs"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_sentences=df['tokens'].tolist()\n",
        "labels_1=df['subject_mask_tokens'].tolist()\n",
        "labels_2=df['polarized_mask_tokens'].tolist()\n",
        "padded_sentences = pad_sequences(tokenized_sentences, maxlen=max_sequence_length)\n",
        "padded_labels_1 = pad_sequences(labels_1, maxlen=max_sequence_length)\n",
        "padded_labels_2 = pad_sequences(labels_2, maxlen=max_sequence_length)\n",
        "split_index = int(train_val_split * len(padded_sentences))\n",
        "\n",
        "train_sentences = padded_sentences[:split_index]\n",
        "train_labels_1 = padded_labels_1[:split_index]\n",
        "train_labels_2 = padded_labels_2[:split_index]\n",
        "\n",
        "val_sentences = padded_sentences[split_index:]\n",
        "val_labels_1 = padded_labels_1[split_index:]\n",
        "val_labels_2 = padded_labels_2[split_index:]"
      ],
      "metadata": {
        "id": "OrXk6PjcUV31"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = Input(shape=(max_sequence_length,))\n",
        "embedding_layer = Embedding(vocab_size, embedding_dim, input_length=max_sequence_length)(input_layer)\n",
        "gru_layer = GRU(gru_units, return_sequences=True)(embedding_layer)\n",
        "\n",
        "output_layer_1 = TimeDistributed(Dense(2, activation='sigmoid'))(gru_layer)\n",
        "output_layer_2 = TimeDistributed(Dense(2, activation='sigmoid'))(gru_layer)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=[output_layer_1, output_layer_2])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "-VCgKMCPbI5X"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "batch_size = 32\n",
        "\n",
        "history = model.fit(train_sentences, [train_labels_1, train_labels_2], validation_data=(val_sentences, [val_labels_1, val_labels_2]), epochs=epochs, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "3e8WXZZTbNws"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}